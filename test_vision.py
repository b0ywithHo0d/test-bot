import streamlit as st
import openai
import base64
import requests
import json
from PIL import Image
from io import BytesIO

# âœ… API í‚¤ ì„¤ì •
openai.api_key = st.secrets["openai_api_key"]["openai_api_key"]
drug_api_key = st.secrets["service_key"]["drug_api_key"]

# âœ… Streamlit UI
st.title("ğŸ’Š ì•½ ì‚¬ì§„ ë¶„ì„ & ì„±ë¶„ ìƒí˜¸ì‘ìš© ì²´í¬ë´‡")

uploaded_images = st.file_uploader("ğŸ“· ì•½ ì‚¬ì§„ì„ í•˜ë‚˜ ì´ìƒ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "png", "jpeg"], accept_multiple_files=True)

if uploaded_images:
    extracted_ingredients = []

    for idx, img_file in enumerate(uploaded_images):
        st.image(img_file, caption=f"ì•½ ì´ë¯¸ì§€ {idx + 1}", use_column_width=True)

        # OpenAI Vision API í˜¸ì¶œ
        base64_image = base64.b64encode(img_file.getvalue()).decode("utf-8")
        vision_response = openai.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ì´ ì•½ì˜ ì£¼ì„±ë¶„ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•´ì¤˜."},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
                    ],
                }
            ],
            max_tokens=300
        )

        extracted_text = vision_response.choices[0].message.content.strip()
        extracted_ingredients.append((f"ì•½ {idx + 1}", extracted_text))
        st.markdown(f"ğŸ§¾ **ì•½ {idx + 1} ì„±ë¶„ ì¶”ì¶œ:**\n```\n{extracted_text}\n```")

    # âœ… ì˜ì•½í’ˆ API ì •ë³´ í™•ì¸
    st.markdown("---")
    st.subheader("ğŸ“¡ eì•½ì€ìš” APIë¡œ ì„±ë¶„ ì •ë³´ ì¡°íšŒ")

    for name, text in extracted_ingredients:
        st.markdown(f"ğŸ” **{name}**")
        query = text.split("\n")[0]  # ê°€ì¥ ëŒ€í‘œë˜ëŠ” ì¤„ë§Œ ì‚¬ìš© (ë³´í†µ ì„±ë¶„ ì´ë¦„ì¼ í™•ë¥  ë†’ìŒ)
        url = f"https://apis.data.go.kr/1471000/DrbEasyDrugInfoService/getDrbEasyDrugList"
        params = {
            "serviceKey": drug_api_key,
            "itemName": query,
            "type": "json",
            "pageNo": 1,
            "numOfRows": 1
        }
        try:
            res = requests.get(url, params=params, timeout=5)
            data = res.json()
            if "body" in data["response"] and "items" in data["response"]["body"]:
                item = data["response"]["body"]["items"][0]
                st.markdown(f"ğŸ’¡ **{item['itemName']}**")
                st.markdown(f"- **íš¨ëŠ¥/íš¨ê³¼:** {item.get('efcyQesitm', 'ì •ë³´ ì—†ìŒ')}")
                st.markdown(f"- **ì£¼ì˜ì‚¬í•­:** {item.get('atpnQesitm', 'ì •ë³´ ì—†ìŒ')}")
            else:
                st.warning(f"'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPTê°€ ë¶„ì„í•œ ì„±ë¶„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´ ë¶„ì„í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"API ì˜¤ë¥˜ ë°œìƒ: {e}")

    # âœ… GPTë¥¼ í†µí•œ ì„±ë¶„ ìƒí˜¸ì‘ìš© ë¶„ì„
    st.markdown("---")
    st.subheader("ğŸ§  GPT ìƒí˜¸ì‘ìš© ë¶„ì„")

    full_ingredient_summary = "\n".join([f"{name} ì„±ë¶„: {text}" for name, text in extracted_ingredients])

    analysis_prompt = f"""
ë‹¤ìŒì€ ì—¬ëŸ¬ ì•½ì˜ ì£¼ìš” ì„±ë¶„ ëª©ë¡ì…ë‹ˆë‹¤. ì´ ì•½ë“¤ì„ í•¨ê»˜ ë³µìš©í•  ë•Œ ì„±ë¶„ ê°„ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ„í—˜ ìš”ì†Œë‚˜ ì£¼ì˜ì‚¬í•­ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì˜í•™ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ìˆ˜ì¤€ì˜ ì¡°ì–¸ì´ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ë‹¨ìˆœíˆ ê²¹ì¹˜ëŠ” ì„±ë¶„, ê³¼ë‹¤ë³µìš© ê°€ëŠ¥ì„±, ê¸ˆê¸° ì¡°í•© ë“±ì„ ì¤‘ì ìœ¼ë¡œ ì•Œë ¤ì¤˜.
"""

    interaction_response = openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì•½í•™ ì „ë¬¸ê°€ë¡œ, ì•½ ì„±ë¶„ì˜ ìƒí˜¸ì‘ìš©ì— ëŒ€í•´ ì¡°ì–¸í•´ì£¼ëŠ” ì—­í• ì´ì•¼."},
            {"role": "user", "content": analysis_prompt}
        ],
        temperature=0.7,
        max_tokens=700
    )

    st.markdown("ğŸ§ª **GPT ë¶„ì„ ê²°ê³¼:**")
    st.info(interaction_response.choices[0].message.content.strip())



